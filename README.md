# Iterative-Saliency-via-Dynamic-Image-Region-Partitioning
Vison Old, Vision New. After reading this paper , you will get new insights of computer vision. For more information, please contact with me via gmail.

Abstract—A  novel  object  level  saliency  model  is  proposed  in  this letter  via  iterating  saliency  classification  difference  on  dynamic  image region  partitioning.  First,  the  model  proposed  solved  three  problems which  is  caused  by  static  background  based  methods.  Then  dynamic background  is  represented  and  computed  on  the  input  image  via dynamic  image  partitioning.  Unlike  existing  static  background  based methods,  we  calculate  saliency  difference  based  on  dynamic background  rather  than  static  image  region.  This  strategy  makes  the saliency  result  more  precisely  to  the  location  of  image  objects.  We apply  two  saliency  classification  difference  on  the  dynamic background.  Second,  saliency  classification  difference  is  iterated  on saliency  maps  generating  by  dynamic  image  region  partitioning.  This makes  the  saliency  results  more  robust.  To  get  a  more  robust  result, the  dynamic  image  partitioning  is  operated  on  an  image  in  four directions  (i.e.,  left  to  right,  right  to  left,  top  to  bottom,  bottom  to  top). Third,  the  final  saliency  map  is  generated  by  combining  four  saliency maps  based  on  four  direction  scanning.  The  four  direction combination  enables  the  proposed  method  to  uniformly  highlight  the salient  object  and  simultaneously  suppress  the  background  effectively. Extensive  experiments  on  two  large  dataset  demonstrate  that  the proposed  method  performs  favorably  against  the  classic  methods  in terms of  accuracy  and efficiency. Index  Terms—Dynamic  image  region  partitioning,  iterating, dynamic  background,  four  direction  scanning,  saliency  map. 

In  this  letter,  we  present  a  bottom-up  object  level  saliency detection  model  by  exploiting  dynamic  image  region  partitioning, iterating  saliency  difference  and  four  direction  scanning.  Firstly,  we get  more  precise  results  than  the  background  based  methods  with dynamic  image  region  partitioning.  Secondly,  iterating  the  saliency classification  difference  automatically  separates  the  salient  object and  the  background.  Thirdly,  the  four  direction  scanning  makes  our algorithm  more  robust.  Saliency  maps  on  a  large  public  dataset demonstrate  that  the  proposed  method  can  highlight  the  whole object  region  uniformly  and  suppress  the  background  region effectively.  In  addition,  the  proposed  method  performs  favorably against  the  classic  methods  in  accuracy,  which  shows  that  the proposed  dynamic  image  region  partitioning,  iterating  saliency classification  results  and  four  direction  scanning  are  useful  for saliency  detection.  In  the  future  work,  we  will  investigate  a  more complicated  classification  strategy  to  boost  classification  results  at different  scales  and  explore  more  applications  of  dynamic  image region  partitioning  to  other  saliency  algorithms. 

I.  INTRODUCTION S ALIENT  object  detection  is  the  process  of  identifying  the most  distinguishable  object  that  human  vision  system interested  in  a  complex  scene  and  a  key  attentional mechanism  related  to  the  basic  survival  skills.  At  the  era  of  big mount  of  image  and  video  data,  it  is  needed  to  focus  the  finite computing  resources  to  let  computer  have  the  ability  to  understand the  surrounding  environment  as  we  humans  do.  Visual  saliency plays  an  important  role  for  intelligent  computer  vision  and multimedia  applications.  The  saliency-based  applications  can  be normally  classified  into  six  categories  nowadays,  including retargeting  [1],  advertising  [2],  retrieval  [3],  summarization  [4], compression  [5]  and  recognition [6].   Saliency  models  can  be  generally  categorized  as  two  directions either  task-independent  bottom-up  saliency  or  task-driven  top-down saliency  from  research  interests.  Bottom-up  saliency  [7]-[18]  is  fast, involuntary,  stimulus-driven  and  top-down  saliency  [20]  is  slower, voluntary  and  goal-driven.  Borji  et  al.  [21]  notes  that  the  two researching  waves  of  saliency  detection  are  eye  fixation  prediction [7]-[10]  and  salient  object  detection  [11]-[18].   Researches  from  perceptual  research  [22-24]  indicate  that  the most  influential  factor  in  low-level  visual  saliency  is  contrast. However,  the  calculation  of  contrast  in  previous  works  is  based  on various  different  types  of  image  features,  including  color  variation of  individual  pixels,  edges  and  gradients,  spatial  frequencies, structure  and  distribution  of  image  patches,  histograms,  multi-scale descriptors,  or  combinations  thereof  [15].  The  definition  of  saliency difference  is  often  being  calculated  only  once  and  most  of  them  all rely  on  complex  classification  models  to  detect  the  salient  image region.  Recently,  methods  that  exploits  background  priors  are proposed  for  saliency  detection  [17]-[19].  They  model  saliency   detection  as  a  ranking  problem.  By  using  the  image  patches  on  the image  boundary  as  queries,  the  remaining  nodes  are  ranked  based  on their  relevance  to  the  given  query,  which  usually  yields  wrong ranking  results  when  object  taking  place  on  image  boundary,  color feature  of  large  area  on  the  image  boundary  is  almost  the  same  as salient  object  or  original image  with  30  pixels  pure  black  rectangle  on image  border.   Considering  all  the  above  mentioned  issues,  we  propose  a  bottomup  saliency  detection  model  based  on  following  properties:   • Structure.  To  highlight  salient  pixels  uniformly  and  efficiently, we  exploiting  image  structure  for  saliency  detection  via superpixels. • Region  contrast.  Local  region  contrast  provides  more  visual information  than  pixels-based  contrast. • Iterative.  Iterating  ranking  results  exaggerates  the  ranking difference  of  superpixels. • Dynamic  image  region  partitioning.  Dynamic  image  region partitioning  makes  the  dynamic  background  possible.  In contrast  to  static  background-based  methods,  dynamic background yields more  precisely  saliency  detection  results. • Four  direction  scanning.  Four  direction  scanning  makes  the proposed  saliency  model  more  robust. Based  on  these  properties,  this  letter  proposes  a  salient  object detection  model  based  on  iterating  saliency  classification  difference, dynamic  image partitioning  and  four  direction  scanning.   The  most  related  works  are  [17]-[19].  They  are  all  static background-based  methods  and  doing  saliency  classification  by  a complex  mathematical  model.  Unlike  their  works,  we  have  four  main contributions as  follows.   • First,  dynamic  background  is  generated  to  replace  the  static background  by  exploiting  dynamic  image  region  partitioning. • Second,  iterating  saliency  classification  difference  gradually exaggerates  the  saliency  difference  among  superpixels  so  that salient  object  and  image  background  can  separate  automatically finally. • Third,  four  direction  scanning  makes  the  final  saliency detection  result  more  robust,  which  highlights  the  salient  object and  suppressing the  background  uniformly. • Fourth,  the  saliency  classification  strategy  that  we  choose  is rather  simple  for  that  we  only  use  Euclidean  distance  as  the measurement  approach. We  use  the  Precision  and  Recall  (P-R)  curve  and  Mean  Absolute Error  (MAE)  to  evaluate  the  proposed  algorithm  and  11  state-of-art methods  on  two  benchmark  datasets.  Fig.  1  shows  samples  of saliency  maps  generated  by  state-of-art  methods  and  our  methods. Both quantitatively and  qualitatively  experimental  results demonstrate  that  our  algorithm  performs  favorably  among  all  the evaluated  methods,  which  bear  out  the  validity  of  the  principles  used in  proposed  saliency  model. 
